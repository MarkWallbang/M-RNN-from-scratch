{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils for M-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def live_plot(data,missing,ground_truth,figsize=(12,4), title=''):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.ylim(-1.5,3.5)\n",
    "    plt.xlim(-2,51)\n",
    "    missing=missing.cpu()\n",
    "    x= np.arange(data.shape[1])\n",
    "    colors=[\"blue\",\"green\",\"red\"]\n",
    "    for dim in range(data.shape[0]):\n",
    "        plt.plot(x,data[dim].cpu(),c=colors[dim])\n",
    "        plt.plot(x,ground_truth[dim].cpu(),alpha=0.5,linestyle=\"dashed\",c=colors[dim])\n",
    "        plt.scatter(x[missing[dim]],(data[dim][missing[dim]]).cpu(),c=colors[dim])\n",
    "\n",
    "    line = Line2D([], [], label='ground truth', color='blue', linestyle=\"dashed\")\n",
    "    line2 = Line2D([], [], label='reconstruction', color='blue')\n",
    "    line3 = Line2D([], [], label='missing points', color='blue',marker=\"o\")\n",
    "    \n",
    "    plt.legend(handles=[line,line2,line3], numpoints=1,loc=3)\n",
    "    plt.title(\"Epoch {}\".format(int(title)+1))\n",
    "#     plt.grid(True)\n",
    "    plt.xlabel('axis x')\n",
    "    plt.ylabel('axis y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, mask, delta):\n",
    "    indices = np.arange(data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices= indices[:int(data.shape[0]*0.8)]\n",
    "    test_indices = indices[int(data.shape[0]*0.8):]\n",
    "\n",
    "    data_train = data[train_indices]\n",
    "    mask_train = mask[train_indices]\n",
    "    delta_train = delta[train_indices]\n",
    "    data_test = data[test_indices]\n",
    "    mask_test = mask[test_indices]\n",
    "    delta_test = delta[test_indices]\n",
    "    return data_train,mask_train,delta_train,data_test,mask_test,delta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute2st(v, ndim_en=1):\n",
    "    \"\"\"\n",
    "    Permute last ndim_en of an array v to the first\n",
    "    :type v: torch.Tensor\n",
    "    :type ndim_en: int\n",
    "    :rtype: torch.Tensor\n",
    "    \"\"\"\n",
    "    nd = v.ndimension()\n",
    "    return v.permute([*range(-ndim_en, 0)] + [*range(nd - ndim_en)])\n",
    "def permute2en(v, ndim_st=1):\n",
    "    \"\"\"\n",
    "    Permute first ndim_en of an array v to the last\n",
    "    :type v: torch.Tensor\n",
    "    :type ndim_st: int\n",
    "    :rtype: torch.Tensor\n",
    "    \"\"\"\n",
    "    nd = v.ndimension()\n",
    "    return v.permute([*range(ndim_st, nd)] + [*range(ndim_st)])\n",
    "def unblock_diag(m, n=None, size_block=None):\n",
    "    \"\"\"\n",
    "    The inverse of block_diag(). Not vectorized yet.\n",
    "    :param m: block diagonal matrix\n",
    "    :param n: int. Number of blocks\n",
    "    :size_block: torch.Size. Size of a block.\n",
    "    :return: tensor unblocked such that the last sizes are [n] + size_block\n",
    "    \"\"\"\n",
    "    # not vectorized yet\n",
    "    if size_block is None:\n",
    "        size_block = torch.Size(torch.tensor(m.shape[-2:]) // n)\n",
    "    elif n is None:\n",
    "        n = m.shape[-2] // torch.tensor(size_block[0])\n",
    "        assert n == m.shape[-1] // torch.tensor(size_block[1])\n",
    "        \n",
    "    m = permute2st(m, 2)\n",
    "\n",
    "    res = torch.zeros(torch.Size([n]) + size_block + m.shape[2:])\n",
    "    for i_block in range(n):\n",
    "        st_row = size_block[0] * i_block\n",
    "        en_row = size_block[0] * (i_block + 1)\n",
    "        st_col = size_block[1] * i_block\n",
    "        en_col = size_block[1] * (i_block + 1)\n",
    "        res[i_block,:] = m[st_row:en_row, st_col:en_col, :]\n",
    "\n",
    "    return permute2en(res, 3)\n",
    "def block_diag(m):\n",
    "    \"\"\"\n",
    "    Make a block diagonal matrix along dim=-3\n",
    "    EXAMPLE:\n",
    "    block_diag(torch.ones(4,3,2))\n",
    "    should give a 12 x 8 matrix with blocks of 3 x 2 ones.\n",
    "    Prepend batch dimensions if needed.\n",
    "    You can also give a list of matrices.\n",
    "    :type m: torch.Tensor, list\n",
    "    :rtype: torch.Tensor\n",
    "    \"\"\"\n",
    "    if type(m) is list:\n",
    "        m = torch.cat([m1.unsqueeze(-3) for m1 in m], -3)\n",
    "\n",
    "    d = m.dim()\n",
    "    n = m.shape[-3]\n",
    "    siz0 = m.shape[:-3]\n",
    "    siz1 = m.shape[-2:]\n",
    "    m2 = m.unsqueeze(-2)\n",
    "    eye = attach_dim(torch.eye(n).unsqueeze(-2), d - 3, 1)\n",
    "    return (m2 * eye).reshape(\n",
    "        siz0 + torch.Size(torch.tensor(siz1) * n)\n",
    "    )\n",
    "\n",
    "def attach_dim(v, n_dim_to_prepend=0, n_dim_to_append=0):\n",
    "    return v.reshape(\n",
    "        torch.Size([1] * n_dim_to_prepend)\n",
    "        + v.shape\n",
    "        + torch.Size([1] * n_dim_to_append))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return x * (x > 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
